2023-01-02 11:50:36,051 INFO    MainThread:84456 [wandb_setup.py:_flush():69] setting env: {}
2023-01-02 11:50:36,051 WARNING MainThread:84456 [wandb_setup.py:_flush():69] could not find program at scripts/black_box_opt.py
2023-01-02 11:50:36,051 INFO    MainThread:84456 [wandb_setup.py:_flush():69] setting login settings: {}
2023-01-02 11:50:36,051 INFO    MainThread:84456 [wandb_init.py:_log_setup():336] Logging user logs to /Users/kofoed/Documents/repos/lambo_kofoed/data/experiments/test/wandb/run-20230102_115036-34aesbej/logs/debug.log
2023-01-02 11:50:36,051 INFO    MainThread:84456 [wandb_init.py:_log_setup():337] Logging internal logs to /Users/kofoed/Documents/repos/lambo_kofoed/data/experiments/test/wandb/run-20230102_115036-34aesbej/logs/debug-internal.log
2023-01-02 11:50:36,052 INFO    MainThread:84456 [wandb_init.py:init():369] calling init triggers
2023-01-02 11:50:36,052 INFO    MainThread:84456 [wandb_init.py:init():374] wandb.init called with sweep_config: {}
config: {'config/logger/_target_': 'upcycle.logging.DataFrameLogger', 'config/logger/log_dir': 'data/experiments/test/None/2023-01-02_11-50-35', 'config/task/_target_': 'lambo.tasks.chem.chem.ChemTask', 'config/task/obj_dim': 2, 'config/task/obj_properties': ['logP', 'qed'], 'config/task/log_prefix': 'chem', 'config/task/num_start_examples': 512, 'config/task/batch_size': 16, 'config/task/max_num_edits': None, 'config/task/max_len': 128, 'config/task/max_ngram_size': 1, 'config/task/allow_len_change': True, 'config/task/worst_ratio': 1.0, 'config/task/best_ratio': 0.0, 'config/acquisition/_target_': 'lambo.acquisitions.ehvi.NoisyEHVI', 'config/acquisition/num_samples': 2, 'config/acquisition/batch_size': 16, 'config/encoder/_target_': 'lambo.models.lm_elements.LanguageModel', 'config/encoder/name': 'mlm_cnn', 'config/encoder/model/_target_': 'lambo.models.shared_elements.mCNN', 'config/encoder/model/tokenizer/_target_': 'lambo.tasks.chem.utils.SELFIESTokenizer', 'config/encoder/model/max_len': 128, 'config/encoder/model/embed_dim': 64, 'config/encoder/model/latent_dim': 16, 'config/encoder/model/out_dim': 2, 'config/encoder/model/kernel_size': 5, 'config/encoder/model/p': 0.0, 'config/encoder/model/layernorm': True, 'config/encoder/model/max_len_delta': 0, 'config/encoder/batch_size': 32, 'config/encoder/num_epochs': 128, 'config/encoder/patience': 32, 'config/encoder/lr': 0.001, 'config/encoder/max_shift': 0, 'config/encoder/mask_ratio': 0.125, 'config/optimizer/_target_': 'lambo.optimizers.lambo.LaMBO', 'config/optimizer/_recursive_': False, 'config/optimizer/num_rounds': 64, 'config/optimizer/num_gens': 2, 'config/optimizer/num_opt_steps': 32, 'config/optimizer/patience': 32, 'config/optimizer/lr': 0.1, 'config/optimizer/concentrate_pool': 1, 'config/optimizer/mask_ratio': 0.125, 'config/optimizer/resampling_weight': 1.0, 'config/optimizer/encoder_obj': 'mlm', 'config/optimizer/optimize_latent': True, 'config/optimizer/position_sampler': 'uniform', 'config/optimizer/entropy_penalty': 0.01, 'config/optimizer/window_size': 1, 'config/optimizer/latent_init': None, 'config/optimizer/algorithm/_target_': 'pymoo.algorithms.soo.nonconvex.ga.GA', 'config/optimizer/algorithm/pop_size': 16, 'config/optimizer/algorithm/n_offsprings': None, 'config/optimizer/algorithm/sampling/_target_': 'lambo.optimizers.sampler.BatchSampler', 'config/optimizer/algorithm/sampling/batch_size': 16, 'config/optimizer/algorithm/crossover/_target_': 'lambo.optimizers.crossover.BatchCrossover', 'config/optimizer/algorithm/crossover/prob': 0.25, 'config/optimizer/algorithm/crossover/prob_per_query': 0.25, 'config/optimizer/algorithm/mutation/_target_': 'lambo.optimizers.mutation.LocalMutation', 'config/optimizer/algorithm/mutation/prob': 1.0, 'config/optimizer/algorithm/mutation/eta': 16, 'config/optimizer/algorithm/mutation/safe_mut': False, 'config/optimizer/algorithm/eliminate_duplicates': True, 'config/tokenizer/_target_': 'lambo.tasks.chem.utils.SELFIESTokenizer', 'config/surrogate/_target_': 'lambo.models.gp_models.MultiTaskExactGP', 'config/surrogate/max_shift': 0, 'config/surrogate/mask_size': 0, 'config/surrogate/bootstrap_ratio': None, 'config/surrogate/min_num_train': 128, 'config/surrogate/task_noise_init': 0.25, 'config/surrogate/gp_lr': 0.005, 'config/surrogate/enc_lr': 0.005, 'config/surrogate/bs': 32, 'config/surrogate/eval_bs': 16, 'config/surrogate/num_epochs': 256, 'config/surrogate/holdout_ratio': 0.2, 'config/surrogate/early_stopping': True, 'config/surrogate/patience': 32, 'config/surrogate/eval_period': 2, 'config/surrogate/out_dim': 2, 'config/surrogate/feature_dim': 2, 'config/surrogate/encoder_wd': 0.0001, 'config/surrogate/rank': None, 'config/surrogate/task_covar_prior/_target_': 'gpytorch.priors.LKJCovariancePrior', 'config/surrogate/task_covar_prior/n': 2, 'config/surrogate/task_covar_prior/eta': 2.0, 'config/surrogate/task_covar_prior/sd_prior/_target_': 'gpytorch.priors.SmoothedBoxPrior', 'config/surrogate/task_covar_prior/sd_prior/a': 0.0001, 'config/surrogate/task_covar_prior/sd_prior/b': 1.0, 'config/surrogate/data_covar_module/_target_': 'gpytorch.kernels.MaternKernel', 'config/surrogate/data_covar_module/ard_num_dims': 2, 'config/surrogate/data_covar_module/lengthscale_prior/_target_': 'gpytorch.priors.NormalPrior', 'config/surrogate/data_covar_module/lengthscale_prior/loc': 0.7, 'config/surrogate/data_covar_module/lengthscale_prior/scale': 0.01, 'config/surrogate/likelihood/_target_': 'gpytorch.likelihoods.MultitaskGaussianLikelihood', 'config/surrogate/likelihood/num_tasks': 2, 'config/surrogate/likelihood/has_global_noise': False, 'config/surrogate/likelihood/noise_constraint/_target_': 'gpytorch.constraints.GreaterThan', 'config/surrogate/likelihood/noise_constraint/lower_bound': 0.0001, 'config/seed': 0, 'config/trial_id': 0, 'config/project_name': 'lambo', 'config/version': 'v0.2.1', 'config/data_dir': 'data/experiments', 'config/exp_name': 'test', 'config/job_name': None, 'config/timestamp': '2023-01-02_11-50-35', 'config/log_dir': 'data/experiments/test', 'config/wandb_mode': 'online'}
2023-01-02 11:50:36,052 INFO    MainThread:84456 [wandb_init.py:init():418] starting backend
2023-01-02 11:50:36,052 INFO    MainThread:84456 [backend.py:_multiprocessing_setup():69] multiprocessing start_methods=spawn,fork,forkserver, using: spawn
2023-01-02 11:50:36,065 INFO    MainThread:84456 [backend.py:ensure_launched():123] starting backend process...
2023-01-02 11:50:36,075 INFO    MainThread:84456 [backend.py:ensure_launched():127] started backend process with pid: 84467
2023-01-02 11:50:36,077 INFO    MainThread:84456 [wandb_init.py:init():423] backend started and connected
2023-01-02 11:50:36,082 INFO    MainThread:84456 [wandb_init.py:init():465] updated telemetry
2023-01-02 11:50:36,083 INFO    MainThread:84456 [wandb_init.py:init():484] communicating current version
2023-01-02 11:50:36,775 INFO    MainThread:84456 [wandb_init.py:init():489] got version response upgrade_message: "wandb version 0.13.7 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"

2023-01-02 11:50:36,775 INFO    MainThread:84456 [wandb_init.py:init():497] communicating run to backend with 30 second timeout
2023-01-02 11:50:37,054 INFO    MainThread:84456 [wandb_init.py:init():522] starting run threads in backend
2023-01-02 11:50:42,063 INFO    MainThread:84456 [wandb_run.py:_console_start():1554] atexit reg
2023-01-02 11:50:42,064 INFO    MainThread:84456 [wandb_run.py:_redirect():1401] redirect: SettingsConsole.REDIRECT
2023-01-02 11:50:42,064 INFO    MainThread:84456 [wandb_run.py:_redirect():1406] Redirecting console.
2023-01-02 11:50:42,065 INFO    MainThread:84456 [wandb_run.py:_redirect():1468] Redirects installed.
2023-01-02 11:50:42,065 INFO    MainThread:84456 [wandb_init.py:init():546] run started, returning control to user process
2023-01-02 11:50:48,779 INFO    MainThread:84456 [wandb_run.py:_atexit_cleanup():1524] got exitcode: 0
2023-01-02 11:50:48,780 INFO    MainThread:84456 [wandb_run.py:_restore():1496] restore
2023-01-02 11:50:51,029 INFO    MainThread:84456 [wandb_run.py:_wait_for_finish():1646] got exit ret: file_counts {
  wandb_count: 1
}
pusher_stats {
  uploaded_bytes: 875
  total_bytes: 875
}

2023-01-02 11:50:51,322 INFO    MainThread:84456 [wandb_run.py:_wait_for_finish():1646] got exit ret: file_counts {
  wandb_count: 1
}
pusher_stats {
  uploaded_bytes: 875
  total_bytes: 875
}

2023-01-02 11:50:51,659 INFO    MainThread:84456 [wandb_run.py:_wait_for_finish():1646] got exit ret: file_counts {
  wandb_count: 6
}
pusher_stats {
  uploaded_bytes: 22517
  total_bytes: 22517
}

2023-01-02 11:50:51,765 INFO    MainThread:84456 [wandb_run.py:_wait_for_finish():1646] got exit ret: file_counts {
  wandb_count: 6
}
pusher_stats {
  uploaded_bytes: 22517
  total_bytes: 22517
}

2023-01-02 11:50:51,870 INFO    MainThread:84456 [wandb_run.py:_wait_for_finish():1646] got exit ret: file_counts {
  wandb_count: 6
}
pusher_stats {
  uploaded_bytes: 22517
  total_bytes: 22517
}

2023-01-02 11:50:51,976 INFO    MainThread:84456 [wandb_run.py:_wait_for_finish():1646] got exit ret: file_counts {
  wandb_count: 6
}
pusher_stats {
  uploaded_bytes: 22517
  total_bytes: 22517
}

2023-01-02 11:50:52,079 INFO    MainThread:84456 [wandb_run.py:_wait_for_finish():1646] got exit ret: file_counts {
  wandb_count: 6
}
pusher_stats {
  uploaded_bytes: 22517
  total_bytes: 22517
}

2023-01-02 11:50:52,181 INFO    MainThread:84456 [wandb_run.py:_wait_for_finish():1646] got exit ret: done: true
exit_result {
}
file_counts {
  wandb_count: 6
}
pusher_stats {
  uploaded_bytes: 22517
  total_bytes: 22517
}

2023-01-02 11:50:53,546 INFO    MainThread:84456 [wandb_run.py:_show_summary():1801] rendering summary
2023-01-02 11:50:53,546 INFO    MainThread:84456 [wandb_run.py:_show_history():1839] rendering history
2023-01-02 11:50:53,546 INFO    MainThread:84456 [wandb_run.py:_show_files():1868] logging synced files
